\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{unsrtnat}
\citation{tabula2022tabula}
\citation{cui2024scgpt}
\citation{theodoris2023geneformer}
\citation{elhage2022toy}
\citation{olah2020zoom}
\citation{bricken2023monosemanticity,cunningham2023sparse,templeton2024scaling}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{elhage2022toy}
\citation{cui2024scgpt}
\citation{tabula2022tabula}
\citation{cui2024scgpt}
\citation{theodoris2023geneformer}
\citation{yang2022scbert}
\citation{zhao2024celllm}
\citation{olah2020zoom}
\citation{elhage2022toy}
\citation{cunningham2023sparse}
\citation{bricken2023monosemanticity}
\citation{templeton2024scaling}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Single-Cell Foundation Models}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Mechanistic Interpretability and Sparse Autoencoders}{2}{subsection.2.2}\protected@file@percent }
\citation{cui2024scgpt,theodoris2023geneformer}
\citation{tabula2022tabula}
\citation{wolf2018scanpy}
\citation{cui2024scgpt}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Cell-type composition of the dataset. Types with $\geq 5$ cells are shown.}}{3}{table.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:celltypes}{{1}{3}{Cell-type composition of the dataset. Types with $\geq 5$ cells are shown}{table.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Interpretability in Biological Models}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Foundation Model and Activation Extraction}{3}{subsection.3.2}\protected@file@percent }
\citation{bricken2023monosemanticity}
\citation{kingma2014adam}
\citation{benjamini1995controlling}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Sparse Autoencoder Architecture and Training}{4}{subsection.3.3}\protected@file@percent }
\newlabel{eq:encoder}{{2}{4}{Sparse Autoencoder Architecture and Training}{equation.3.2}{}}
\newlabel{eq:decoder}{{3}{4}{Sparse Autoencoder Architecture and Training}{equation.3.3}{}}
\newlabel{eq:loss}{{4}{4}{Sparse Autoencoder Architecture and Training}{equation.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Feature Analysis}{4}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Cell-type specificity.}{4}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gene attribution.}{4}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gene set enrichment.}{4}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Comparison with PCA.}{4}{section*.5}\protected@file@percent }
\citation{bricken2023monosemanticity}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces SAE training results across layers and sparsity levels ($M = 2{,}048$). $L_0$: average number of active features per input. $R^2$: variance explained. Dead: features activating on $<1\%$ of inputs.}}{5}{table.caption.6}\protected@file@percent }
\newlabel{tab:training}{{2}{5}{SAE training results across layers and sparsity levels ($M = 2{,}048$). $L_0$: average number of active features per input. $R^2$: variance explained. Dead: features activating on $<1\%$ of inputs}{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Comparison of low vs.\ high $\lambda $ regimes. Low $\lambda $ achieves near-perfect reconstruction but no meaningful sparsity.}}{5}{table.caption.7}\protected@file@percent }
\newlabel{tab:training_old}{{3}{5}{Comparison of low vs.\ high $\lambda $ regimes. Low $\lambda $ achieves near-perfect reconstruction but no meaningful sparsity}{table.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{5}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Sparsity Requires Strong Regularisation}{5}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Layer Progression of Feature Specificity}{5}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces SAE features vs.\ PCA components for cell-type discrimination and interpretability (layer 11, $\lambda = $~\textcolor {orange}{[TBD: best]}).}}{6}{table.caption.8}\protected@file@percent }
\newlabel{tab:comparison}{{4}{6}{SAE features vs.\ PCA components for cell-type discrimination and interpretability (layer 11, $\lambda = $~\tbd {best})}{table.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Cell-Type-Specific Features}{6}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Gene Set Enrichment}{6}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Comparison with PCA}{6}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{7}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}SAEs as a Tool for Biological Model Interpretability}{7}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Calibration of Sparsity Regularisation}{7}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Limitations}{7}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Connection to AI Safety}{7}{subsection.5.4}\protected@file@percent }
\bibdata{references}
\bibcite{tabula2022tabula}{{1}{2022}{{The Tabula Sapiens Consortium}}{{}}}
\bibcite{cui2024scgpt}{{2}{2024}{{Cui et~al.}}{{Cui, Wang, Maan, Pang, Luo, Duan, and Wang}}}
\bibcite{theodoris2023geneformer}{{3}{2023}{{Theodoris et~al.}}{{Theodoris, Xiao, Chopra, Chaffin, Al~Sayed, Hill, Manber, Beaver, Henber, and Ellinor}}}
\bibcite{elhage2022toy}{{4}{2022}{{Elhage et~al.}}{{Elhage, Hume, Olsson, Schiefer, Henighan, Kravec, Hatfield-Dodds, Lasenby, Drain, Chen, et~al.}}}
\bibcite{olah2020zoom}{{5}{2020}{{Olah et~al.}}{{Olah, Cammarata, Schubert, Goh, Petrov, and Carter}}}
\bibcite{bricken2023monosemanticity}{{6}{2023}{{Bricken et~al.}}{{Bricken, Templeton, Batson, Chen, Jermyn, Conerly, Turner, Anil, Denison, Askell, et~al.}}}
\bibcite{cunningham2023sparse}{{7}{2023}{{Cunningham et~al.}}{{Cunningham, Ewart, Riggs, Huben, and Sharkey}}}
\bibcite{templeton2024scaling}{{8}{2024}{{Templeton et~al.}}{{Templeton, Conerly, Marcus, Lindsey, Bricken, Chen, Pearce, Citro, Ameisen, Jones, et~al.}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Future Directions}{8}{subsection.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{8}{section.6}\protected@file@percent }
\bibcite{yang2022scbert}{{9}{2022}{{Yang et~al.}}{{Yang, Wang, Wang, Fang, Tang, Huang, Lu, and Yao}}}
\bibcite{zhao2024celllm}{{10}{2024}{{Zhao et~al.}}{{}}}
\bibcite{wolf2018scanpy}{{11}{2018}{{Wolf et~al.}}{{Wolf, Angerer, and Theis}}}
\bibcite{kingma2014adam}{{12}{2014}{{Kingma and Ba}}{{}}}
\bibcite{benjamini1995controlling}{{13}{1995}{{Benjamini and Hochberg}}{{}}}
\gdef \@abspage@last{9}
